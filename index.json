[{"content":"\u003cp\u003e\u003cstrong\u003eTools Used:\u003c/strong\u003e\u003cbr\u003e\n\u003cimg src=\"https://img.shields.io/badge/python-3670A0?\u0026amp;logo=python\u0026amp;logoColor=ffdd54\" alt=\"Python\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Machine%20Learning-yellow\" alt=\"Machine Learning\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/-HuggingFace-FDEE21?\u0026amp;logo=HuggingFace\u0026amp;logoColor=black\" alt=\"Hugging Face\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/PowerBi-yellow?logo=powerbi\" alt=\"PowerBi\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Transformers-blueviolet\" alt=\"Transformers\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Pandas-black?logo=pandas\" alt=\"Pandas\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Jupyter-F37626.svg?\u0026amp;logo=Jupyter\u0026amp;logoColor=white\" alt=\"Jupyter Notebook\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eAs a trainee at Gulf Air, I worked on a project to help the airline handle the huge number of customer emails they receive every day. These emails cover all sorts of topics like baggage, bookings, schedule changes, and more. Before, staff had to read and sort each email manually, which took a lot of time and sometimes led to mistakes.\u003c/p\u003e\n\u003ch1 id=\"project-overview\"\u003eProject Overview\u003c/h1\u003e\n\u003cp\u003eTo address this challenge, I designed and implemented an AI-powered email classification system. The core of the solution uses natural language processing (NLP) techniques using Python and the Hugging Face Transformers library. For the model architecture, I fine-tuned the DeBERTa transformer, which is known for its strong performance on language understanding tasks.\u003c/p\u003e\n\u003ch1 id=\"data-collection--augmentation\"\u003eData Collection \u0026amp; Augmentation\u003c/h1\u003e\n\u003cp\u003eTo ensure the integrity and privacy of the data, I did not use historical company emails. Instead, I collected around 30 real, labeled emails and carefully censored any sensitive information. Recognizing that this was a small dataset, I used data augmentation techniques to expand it:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSynthetic Generation:\u003c/strong\u003e I used the GPT-4o-mini model to generate additional emails based on the 30 examples, creating realistic and diverse samples for each category.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eParaphrasing:\u003c/strong\u003e To further increase the dataset size and variability, I used a fine-tuned version of the T5 model to paraphrase the generated emails. This iterative process continued until I had a dataset of approximately 9,000 labeled emails.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis approach allowed me to build a robust and diverse dataset while maintaining data privacy and integrity.\u003c/p\u003e\n\u003ch1 id=\"model-training--evaluation\"\u003eModel Training \u0026amp; Evaluation\u003c/h1\u003e\n\u003cp\u003eThe final dataset was preprocessed and analyzed using Pandas and Jupyter Notebook for exploratory data analysis and feature engineering. After extensive experimentation and hyperparameter tuning, the fine-tuned DeBERTa model achieved an impressive accuracy of \u003cstrong\u003e98.9%\u003c/strong\u003e on the validation set!\u003c/p\u003e\n\u003ch2 id=\"confusion-matrix\"\u003eConfusion Matrix\u003c/h2\u003e\n\u003cp\u003eHere’s a confusion matrix showing what the model got right and what it got wrong on the validation data:\u003c/p\u003e\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"/images/projects/email-classify-gulfair.png\" alt=\"Confusion Matrix\" style=\"max-width: 500px; width: 90%; display: block; margin: 0 auto;\" /\u003e\n\u003c/div\u003e\n\u003chr\u003e\n\u003ch1 id=\"dashboard\"\u003eDashboard\u003c/h1\u003e\n\u003cp\u003eTo help visualize all the email data, I built a Power BI dashboard that shows important patterns at a glance. First, I created a semantic model in Power BI to organize the data in a logical way - linking email categories and sending dates together.\u003c/p\u003e\n\u003cp\u003eThe dashboard has several helpful views that let staff see:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eWhich types of emails are most common\u003c/li\u003e\n\u003cli\u003eHow email volumes change throughout the week or month\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHere is a screenshot of the dashboard:\u003c/p\u003e\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"/images/projects/email-classifier-dashboard.png\" alt=\"Confusion Matrix\" style=\"max-width: 800px; width: 90%; display: block; margin: 0 auto;\" /\u003e\n  \u003cp\u003e\u003cem\u003eNote: The data in this image is synthetic data and is not real.\u003c/em\u003e\u003c/p\u003e\n\u003c/div\u003e\n\u003chr\u003e\n\u003ch1 id=\"impact\"\u003eImpact\u003c/h1\u003e\n\u003cp\u003eUsing the solution I developed could help the company respond to customers faster by automatically routing emails to the right department. It reduces the workload on support teams and lowers operational costs by eliminating the need for manual sorting. But most importantly, it allows Gulf Air to quickly identify common customer concerns and complaints, helping the company improve its services based on real-time feedback.\u003c/p\u003e\n","description":"An AI-powered solution to classify incoming emails for Gulf Air, improving response times and operational efficiency.","image":"/images/projects/email-classifier-dashboard.png","permalink":"https://al-sayed1.github.io/projects/gulf-air-email-classifier/","title":"Gulf Air Email Classifier"},{"content":"\u003cp\u003e\u003cstrong\u003eTools Used:\u003c/strong\u003e\u003cbr\u003e\n\u003cimg src=\"https://img.shields.io/badge/python-3670A0?\u0026amp;logo=python\u0026amp;logoColor=ffdd54\" alt=\"Python\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/TensorFlow-FF6F00?logo=tensorflow\u0026amp;logoColor=white\" alt=\"TensorFlow\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Keras-D00000?logo=keras\u0026amp;logoColor=white\" alt=\"Keras\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/pandas-150458?logo=pandas\u0026amp;logoColor=white\" alt=\"pandas\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Jupyter-F37626?logo=jupyter\u0026amp;logoColor=white\" alt=\"Jupyter\"\u003e\u003c/p\u003e\n\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eDetecting kidney stones in medical images is really important, but it can take a lot of time and effort for doctors. For my project, I wanted to see if I could use deep learning to help make this process easier and faster. So, I built a model using TensorFlow and Keras that can look at a scan and tell if there are kidney stones or not.\u003c/p\u003e\n\u003ch1 id=\"project-overview\"\u003eProject Overview\u003c/h1\u003e\n\u003cp\u003eTo get started, I found a dataset of real ultrasound images of kidneys. Some of the images had kidney stones and some didn’t. I used pandas to help organize the data and Jupyter Notebook to write and test my code.\u003c/p\u003e\n\u003ch1 id=\"how-it-works\"\u003eHow It Works\u003c/h1\u003e\n\u003cp\u003eI built a deep learning model using TensorFlow and Keras. The model is a Convolutional Neural Network (CNN), which is great for classifying grid like data (ultrasound images in my case). I trained the model on the ultrasound images, teaching it to recognize patterns that show whether there are kidney stones or not.\u003c/p\u003e\n\u003ch1 id=\"results\"\u003eResults\u003c/h1\u003e\n\u003cp\u003eAfter training, my model did amazingly well! It got \u003cstrong\u003e100% accuracy\u003c/strong\u003e on the test set, which means it didn’t make any mistakes. Here are the main results:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePrecision:\u003c/strong\u003e 1.00\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRecall:\u003c/strong\u003e 1.00\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eF1-score:\u003c/strong\u003e 1.00\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"confusion-matrix\"\u003eConfusion Matrix\u003c/h2\u003e\n\u003cp\u003eHere’s a confusion matrix from my model’s evaluation. As you can see, it got everything in the validation dataset right:\u003c/p\u003e\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"/images/projects/kidney-stone-confusion-matrix.png\" alt=\"Confusion Matrix\" style=\"max-width: 400px; width: 90%; display: block; margin: 0 auto;\" /\u003e\n\u003c/div\u003e\n\u003ch1 id=\"what-i-did\"\u003eWhat I Did\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eFound and organized the ultrasound image dataset\u003c/li\u003e\n\u003cli\u003eBuilt and trained the deep learning model with TensorFlow and Keras\u003c/li\u003e\n\u003cli\u003eTested the model and made graphs in Jupyter Notebook\u003c/li\u003e\n\u003cli\u003eWrote up everything I did so others can follow along\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"feature-work\"\u003eFeature work\u003c/h1\u003e\n\u003cp\u003eWhile 100% accuracy sounds great, it can sometimes mean that the model is too good at memorizing the training data instead of learning to generalize. This is called overfitting. While my model did well on the test set, it’s important to test it on new data to make sure it works well in real life. I plan to do this by using a different dataset of ultrasound images that I haven’t trained on yet.\u003c/p\u003e\n\u003cp\u003eFor now, I tested the model on images that I found on the internet and it performed well. Here is an example of an image that the model predicted correctly:\u003c/p\u003e\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"/images/projects/kidney-internet-image-classification.png\" alt=\"Kidney Stone Prediction\" style=\"max-width: 400px; width: 90%; display: block; margin: 0 auto;\" /\u003e\n\u003c/div\u003e\n\u003chr\u003e\n\u003cp\u003eThe model predicted that this image has no kidney stones, and it was right! This shows that the model can work well on new images, but I still need to test it on a larger dataset to be sure.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eIf you want to see my code or try it out yourself, check out my GitHub:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/AL-Sayed1/Kidney-Stone-Detection/blob/main/kidney-stone-no-stone.ipynb\" target=\"_blank\" rel=\"noopener\"\u003e\u003cstrong\u003eView code on GitHub\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\n","description":"A deep learning model for detecting kidney stones in medical images with perfect accuracy.","image":"/images/projects/kidney-stone-no-stone.png","permalink":"https://al-sayed1.github.io/projects/kidney-stone-detection/","title":"Kidney Stone Detection using Deep Learning"},{"content":"\u003cp\u003e\u003cstrong\u003eTools Used:\u003c/strong\u003e\u003cbr\u003e\n\u003cimg src=\"https://img.shields.io/badge/Raspberry%20Pi-C51A4A?logo=raspberrypi\u0026amp;logoColor=white\" alt=\"Raspberry Pi\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Linux-FCC624?logo=linux\u0026amp;logoColor=black\" alt=\"Linux\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/python-3670A0?\u0026amp;logo=python\u0026amp;logoColor=ffdd54\" alt=\"Python\"\u003e\u003c/p\u003e\n\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eThis is a project that combines both hardware and software, and it was a really fun experience to work on with my team. The Magic Mirror is basically a smart mirror that can show useful information like the school calendar, the current time, room temperature, news and the weather. What makes it even cooler is that it only lights up when someone is nearby, thanks to a motion sensor. It\u0026rsquo;s perfect for putting in school hallways so students and teachers can quickly check important info as they walk by.\u003c/p\u003e\n\u003ch1 id=\"building-the-frame\"\u003eBuilding the Frame\u003c/h1\u003e\n\u003cp\u003eWe started this project with a focus on sustainability by recycling materials we already had. Our first challenge was creating the frame for the mirror. We found an old wooden chair that was no longer being used and decided to repurpose its wood for our project.\u003c/p\u003e\n\u003cp\u003eWe carefully measured and cut the wood pieces to create a rectangular frame that would perfectly fit our two-way mirror glass. We then painted the wooden frame black.\u003c/p\u003e\n\u003ch1 id=\"display-setup-and-hardware-integration\"\u003eDisplay Setup and Hardware Integration\u003c/h1\u003e\n\u003cp\u003eWe recycled an old computer monitor and carefully disassembled it to fit behind our two-way mirror glass.\u003c/p\u003e\n\u003cp\u003eThe heart of our system was a Raspberry Pi 4b, which we connected to the recycled display via a HDMI to VGA adapter since the display was so old and didn\u0026rsquo;t have a HDMI port. Setting up the Pi involved installing the Magic Mirror² software on Linux, which is a system specifically designed for our usecase!\u003c/p\u003e\n\u003ch1 id=\"sensor-integration\"\u003eSensor Integration\u003c/h1\u003e\n\u003cp\u003eTo make our mirror truly \u0026ldquo;smart,\u0026rdquo; we integrated these two sensors:\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eDHT22 Temperature and Humidity Sensor\u003c/strong\u003e: We wired this sensor to the Raspberry Pi\u0026rsquo;s GPIO pins to provide real-time room temperature and humidity readings. This involved writing Python scripts to read the sensor data and integrate it into the Magic Mirror² interface.\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003ePIR Motion Sensor\u003c/strong\u003e: The motion detection was handled by a PIR (Passive Infrared) sensor connected to the Pi\u0026rsquo;s GPIO pins. I programmed it to detect when someone walks by and automatically turn on the display, then turn it off after a set period of inactivity (10 minutes). This energy-saving feature was necessary for a device meant to run continuously in school hallways.\u003c/p\u003e\n\u003ch1 id=\"software-configuration\"\u003eSoftware Configuration\u003c/h1\u003e\n\u003cp\u003eThe software side involved configuring the Magic Mirror² platform and writing custom modules for our specific needs. I set up the system to display:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSchool calendar integration\u003c/li\u003e\n\u003cli\u003eCurrent time and date\u003c/li\u003e\n\u003cli\u003eLocal weather information\u003c/li\u003e\n\u003cli\u003eReal-time temperature and humidity from our DHT sensor\u003c/li\u003e\n\u003cli\u003eMotion-activated display inactivity time countdown\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"my-role\"\u003eMy Role\u003c/h1\u003e\n\u003cp\u003eThis project was a team effort, and my role included:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eProject Manager\u003c/strong\u003e – I helped organize the team and keep us on track with deadlines and task assignments.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDesign Blueprint\u003c/strong\u003e – I created detailed design blueprints showing the frame dimensions, component placement, and wiring diagrams.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSoftware \u0026amp; Hardware Integration\u003c/strong\u003e – I developed the Python scripts for sensor integration and configured the Magic Mirror² software to work seamlessly with our hardware setup.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"challenges-and-solutions\"\u003eChallenges and Solutions\u003c/h1\u003e\n\u003cp\u003eOne of the biggest challenges was getting the motion sensor calibrated correctly - we had to adjust the sensitivity so it would detect people walking by but not trigger from distant movement. Another challenge was ensuring the recycled monitor fit properly behind the two-way mirror while maintaining good image quality.\u003c/p\u003e\n\u003ch1 id=\"what-i-learned\"\u003eWhat I Learned\u003c/h1\u003e\n\u003cp\u003eWorking on the Magic Mirror taught me a lot about combining hardware and software, the importance of recycling and sustainability in engineering projects, and how important teamwork is for complex builds. The hands-on experience with GPIO programming, sensor integration, and Linux system configuration was invaluable. It was incredibly satisfying to see our recycled materials come together into a functional, interactive device that people could actually use!\u003c/p\u003e\n","description":"A smart mirror that displays school info, time, and weather, and lights up when someone is nearby.","image":"/images/projects/magic-mirror.png","permalink":"https://al-sayed1.github.io/projects/magic-mirror/","title":"Magic Mirror"},{"content":"\u003cp\u003e\u003cstrong\u003eTools Used:\u003c/strong\u003e\u003cbr\u003e\n\u003cimg src=\"https://img.shields.io/badge/python-3670A0?\u0026amp;logo=python\u0026amp;logoColor=ffdd54\" alt=\"Python\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Streamlit-FF4B4B?logo=streamlit\u0026amp;logoColor=white\" alt=\"Streamlit\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/LangChain-blueviolet\" alt=\"LangChain\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/GPT--4o--mini-black\" alt=\"GPT-4o-mini\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/GitHub-181717?logo=github\" alt=\"GitHub\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eNoteCraft\u003c/strong\u003e is a website designed to help students study efficiently by summarizing long documents and lecture videos, and generating questions to evaluate their understanding of the subject. The output notes and flashcards can also be saved as PDFs for easy review and sharing.\u003c/p\u003e\n\u003cp\u003eThis project was developed collaboratively as a team effort. My role included:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eProject Manager\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBackend Development\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFront-End Design\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"features\"\u003eFeatures\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eSummarizes lengthy documents and lecture videos into concise notes.\u003c/li\u003e\n\u003cli\u003eGenerates questions and flashcards to test student comprehension.\u003c/li\u003e\n\u003cli\u003eAllows users to save notes and flashcards as PDF files.\u003c/li\u003e\n\u003cli\u003eAsk AI questions about the lecture and get answers using AI.\u003c/li\u003e\n\u003cli\u003eUser-friendly web interface built with Streamlit.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"my-contributions\"\u003eMy Contributions\u003c/h1\u003e\n\u003cp\u003eAs the project manager, I coordinated the team and ensured timely delivery of milestones. I also led the backend development, integrating LangChain and GPT-4o-mini for advanced summarization and question generation. Additionally, I contributed to the front-end design, focusing on usability and accessibility.\u003c/p\u003e\n\u003ch1 id=\"screenshots\"\u003eScreenshots\u003c/h1\u003e\n\u003cp\u003eHere are some screenshots of the website:\u003c/p\u003e\n\u003cdiv align=\"center\" style=\"margin-bottom: 1.5rem;\"\u003e\n  \u003cimg src=\"/images/projects/notecraft-landing.png\" alt=\"Landing Page\" style=\"max-width: 800px; width: 90%; display: block; margin: 0 auto 1.5rem auto;\" /\u003e\n\u003c/div\u003e\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"/images/projects/note-gen-page.png\" alt=\"Note Generation Page\" style=\"max-width: 800px; width: 90%; display: block; margin: 0 auto;\" /\u003e\n\u003c/div\u003e\n\u003chr\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/AL-Sayed1/NoteCraft\" target=\"_blank\" rel=\"noopener\"\u003e\u003cstrong\u003eView code on GitHub\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\n","description":"A AI tool that turns lengthy lecture videos and documents into concise study notes and interactive flashcards.","image":"/images/projects/notecraft-landing.png","permalink":"https://al-sayed1.github.io/projects/notecraft-ai/","title":"NoteCraft AI"},{"content":"","description":"My gallery :earth_asia:","image":null,"permalink":"https://al-sayed1.github.io/gallery/","title":"Image Gallery"}]