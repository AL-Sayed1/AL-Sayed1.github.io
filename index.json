[{"content":"\u003cp\u003e\u003cstrong\u003eTools Used:\u003c/strong\u003e\u003cbr\u003e\n\u003cimg src=\"https://img.shields.io/badge/python-3670A0?\u0026amp;logo=python\u0026amp;logoColor=ffdd54\" alt=\"Python\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Machine%20Learning-yellow\" alt=\"Machine Learning\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/-HuggingFace-FDEE21?\u0026amp;logo=HuggingFace\u0026amp;logoColor=black\" alt=\"Hugging Face\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/PowerBi-yellow?logo=powerbi\" alt=\"PowerBi\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Transformers-blueviolet\" alt=\"Transformers\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Pandas-black?logo=pandas\" alt=\"Pandas\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Jupyter-F37626.svg?\u0026amp;logo=Jupyter\u0026amp;logoColor=white\" alt=\"Jupyter Notebook\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eAs a trainee at Gulf Air, I worked on a project to help the airline handle the huge number of customer emails they receive every day. These emails cover all sorts of topics like baggage, bookings, schedule changes, and more. Before, staff had to read and sort each email manually, which took a lot of time and sometimes led to mistakes.\u003c/p\u003e\n\u003ch1 id=\"project-overview\"\u003eProject Overview\u003c/h1\u003e\n\u003cp\u003eTo address this challenge, I designed and implemented an AI-powered email classification system. The core of the solution uses natural language processing (NLP) techniques using Python and the Hugging Face Transformers library. For the model architecture, I fine-tuned the DeBERTa transformer, which is known for its strong performance on language understanding tasks.\u003c/p\u003e\n\u003ch1 id=\"data-collection--augmentation\"\u003eData Collection \u0026amp; Augmentation\u003c/h1\u003e\n\u003cp\u003eTo ensure the integrity and privacy of the data, I did not use historical company emails. Instead, I collected around 30 real, labeled emails and carefully censored any sensitive information. Recognizing that this was a small dataset, I used data augmentation techniques to expand it:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSynthetic Generation:\u003c/strong\u003e I used the GPT-4o-mini model to generate additional emails based on the 30 examples, creating realistic and diverse samples for each category.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eParaphrasing:\u003c/strong\u003e To further increase the dataset size and variability, I used a fine-tuned version of the T5 model to paraphrase the generated emails. This iterative process continued until I had a dataset of approximately 9,000 labeled emails.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis approach allowed me to build a robust and diverse dataset while maintaining data privacy and integrity.\u003c/p\u003e\n\u003ch1 id=\"model-training--evaluation\"\u003eModel Training \u0026amp; Evaluation\u003c/h1\u003e\n\u003cp\u003eThe final dataset was preprocessed and analyzed using Pandas and Jupyter Notebook for exploratory data analysis and feature engineering. After extensive experimentation and hyperparameter tuning, the fine-tuned DeBERTa model achieved an impressive accuracy of \u003cstrong\u003e98.9%\u003c/strong\u003e on the validation set!\u003c/p\u003e\n\u003ch2 id=\"confusion-matrix\"\u003eConfusion Matrix\u003c/h2\u003e\n\u003cp\u003eHere’s a confusion matrix showing what the model got right and what it got wrong on the validation data:\u003c/p\u003e\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"/images/projects/email-classify-gulfair.png\" alt=\"Confusion Matrix\" style=\"max-width: 800px; width: 90%; display: block; margin: 0 auto;\" /\u003e\n\u003c/div\u003e\n\u003chr\u003e\n\u003ch1 id=\"impact\"\u003eImpact\u003c/h1\u003e\n\u003cp\u003eUsing the solution I developed could help the company respond to customers faster by automatically routing emails to the right department. It reduces the workload on support teams and lowers operational costs by eliminating the need for manual sorting. But most importantly, it allows Gulf Air to quickly identify common customer concerns and complaints, helping the company improve its services based on real-time feedback.\u003c/p\u003e\n","description":"An AI-powered solution to classify incoming emails for Gulf Air, improving response times and operational efficiency.","image":"/images/projects/email-classify-gulfair.png","permalink":"https://al-sayed1.github.io/projects/gulf-air-email-classifier/","title":"Gulf Air Email Classifier"},{"content":"\u003cp\u003e\u003cstrong\u003eTools Used:\u003c/strong\u003e\u003cbr\u003e\n\u003cimg src=\"https://img.shields.io/badge/python-3670A0?\u0026amp;logo=python\u0026amp;logoColor=ffdd54\" alt=\"Python\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/TensorFlow-FF6F00?logo=tensorflow\u0026amp;logoColor=white\" alt=\"TensorFlow\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Keras-D00000?logo=keras\u0026amp;logoColor=white\" alt=\"Keras\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/pandas-150458?logo=pandas\u0026amp;logoColor=white\" alt=\"pandas\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Jupyter-F37626?logo=jupyter\u0026amp;logoColor=white\" alt=\"Jupyter\"\u003e\u003c/p\u003e\n\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eDetecting kidney stones in medical images is really important, but it can take a lot of time and effort for doctors. For my project, I wanted to see if I could use deep learning to help make this process easier and faster. So, I built a model using TensorFlow and Keras that can look at a scan and tell if there are kidney stones or not.\u003c/p\u003e\n\u003ch1 id=\"project-overview\"\u003eProject Overview\u003c/h1\u003e\n\u003cp\u003eTo get started, I found a dataset of real ultrasound images of kidneys. Some of the images had kidney stones and some didn’t. I used pandas to help organize the data and Jupyter Notebook to write and test my code.\u003c/p\u003e\n\u003ch1 id=\"how-it-works\"\u003eHow It Works\u003c/h1\u003e\n\u003cp\u003eI built a deep learning model using TensorFlow and Keras. The model is a Convolutional Neural Network (CNN), which is great for classifying grid like data (ultrasound images in my case). I trained the model on the ultrasound images, teaching it to recognize patterns that show whether there are kidney stones or not.\u003c/p\u003e\n\u003ch1 id=\"results\"\u003eResults\u003c/h1\u003e\n\u003cp\u003eAfter training, my model did amazingly well! It got \u003cstrong\u003e100% accuracy\u003c/strong\u003e on the test set, which means it didn’t make any mistakes. Here are the main results:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003ePrecision:\u003c/strong\u003e 1.00\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRecall:\u003c/strong\u003e 1.00\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eF1-score:\u003c/strong\u003e 1.00\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"confusion-matrix\"\u003eConfusion Matrix\u003c/h2\u003e\n\u003cp\u003eHere’s a confusion matrix from my model’s evaluation. As you can see, it got everything in the validation dataset right:\u003c/p\u003e\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"/images/projects/kidney-stone-confusion-matrix.png\" alt=\"Confusion Matrix\" style=\"max-width: 400px; width: 90%; display: block; margin: 0 auto;\" /\u003e\n\u003c/div\u003e\n\u003ch1 id=\"what-i-did\"\u003eWhat I Did\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eFound and organized the ultrasound image dataset\u003c/li\u003e\n\u003cli\u003eBuilt and trained the deep learning model with TensorFlow and Keras\u003c/li\u003e\n\u003cli\u003eTested the model and made graphs in Jupyter Notebook\u003c/li\u003e\n\u003cli\u003eWrote up everything I did so others can follow along\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"feature-work\"\u003eFeature work\u003c/h1\u003e\n\u003cp\u003eWhile 100% accuracy sounds great, it can sometimes mean that the model is too good at memorizing the training data instead of learning to generalize. This is called overfitting. While my model did well on the test set, it’s important to test it on new data to make sure it works well in real life. I plan to do this by using a different dataset of ultrasound images that I haven’t trained on yet.\u003c/p\u003e\n\u003cp\u003eFor now, I tested the model on images that I found on the internet and it performed well. Here is an example of an image that the model predicted correctly:\u003c/p\u003e\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"/images/projects/kidney-internet-image-classification.png\" alt=\"Kidney Stone Prediction\" style=\"max-width: 400px; width: 90%; display: block; margin: 0 auto;\" /\u003e\n\u003c/div\u003e\n\u003chr\u003e\n\u003cp\u003eThe model predicted that this image has no kidney stones, and it was right! This shows that the model can work well on new images, but I still need to test it on a larger dataset to be sure.\u003c/p\u003e\n\u003chr\u003e\n\u003cp\u003eIf you want to see my code or try it out yourself, check out my GitHub:\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/AL-Sayed1/Kidney-Stone-Detection/blob/main/kidney-stone-no-stone.ipynb\" target=\"_blank\" rel=\"noopener\"\u003e\u003cstrong\u003eView code on GitHub\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\n","description":"A deep learning model for detecting kidney stones in medical images with perfect accuracy.","image":"/images/projects/kidney-stone-no-stone.png","permalink":"https://al-sayed1.github.io/projects/kidney-stone-detection/","title":"Kidney Stone Detection using Deep Learning"},{"content":"\u003cp\u003e\u003cstrong\u003eTools Used:\u003c/strong\u003e\u003cbr\u003e\n\u003cimg src=\"https://img.shields.io/badge/Raspberry%20Pi-C51A4A?logo=raspberrypi\u0026amp;logoColor=white\" alt=\"Raspberry Pi\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Linux-FCC624?logo=linux\u0026amp;logoColor=black\" alt=\"Linux\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/python-3670A0?\u0026amp;logo=python\u0026amp;logoColor=ffdd54\" alt=\"Python\"\u003e\u003c/p\u003e\n\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eThis is a project that combines both hardware and software, and it was a really fun experience to work on with my team. The Magic Mirror is basically a smart mirror that can show useful school info like the school calendar, the current time, room temperature, and the weather. What makes it even cooler is that it only lights up when someone is nearby, thanks to a motion sensor. It’s perfect for putting in school hallways so students and teachers can quickly check important info as they walk by.\u003c/p\u003e\n\u003ch1 id=\"project-overview\"\u003eProject Overview\u003c/h1\u003e\n\u003cp\u003eWe built the Magic Mirror using a Raspberry Pi 4b running Linux, and used the Magic Mirror2 software. The mirror’s display is actually a monitor behind a two-way mirror, so you can see both your reflection and the information on the screen. The motion sensor is connected to the Raspberry Pi, so the mirror only turns on when it detects movement, which helps save energy.\u003c/p\u003e\n\u003ch1 id=\"my-role\"\u003eMy Role\u003c/h1\u003e\n\u003cp\u003eThis project was a team effort, and my role included:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eProject Manager\u003c/strong\u003e – I helped organize the team and keep us on track.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDesign Blueprint\u003c/strong\u003e – I made the design blueprint for how the mirror would look and work.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSoftware \u0026amp; Hardware Integration\u003c/strong\u003e – I developed the software and made sure it worked smoothly with the hardware.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"what-i-learned\"\u003eWhat I Learned\u003c/h1\u003e\n\u003cp\u003eWorking on the Magic Mirror taught me a lot about combining hardware and software, and how important teamwork is for bigger projects. It was awesome to see everything come together and actually work in real life!\u003c/p\u003e\n","description":"A smart mirror that displays school info, time, and weather, and lights up when someone is nearby.","image":"/images/projects/magic-mirror.png","permalink":"https://al-sayed1.github.io/projects/magic-mirror/","title":"Magic Mirror"},{"content":"\u003cp\u003e\u003cstrong\u003eTools Used:\u003c/strong\u003e\u003cbr\u003e\n\u003cimg src=\"https://img.shields.io/badge/python-3670A0?\u0026amp;logo=python\u0026amp;logoColor=ffdd54\" alt=\"Python\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/Streamlit-FF4B4B?logo=streamlit\u0026amp;logoColor=white\" alt=\"Streamlit\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/LangChain-blueviolet\" alt=\"LangChain\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/GPT--4o--mini-black\" alt=\"GPT-4o-mini\"\u003e\n\u003cimg src=\"https://img.shields.io/badge/GitHub-181717?logo=github\" alt=\"GitHub\"\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003eNoteCraft\u003c/strong\u003e is a website designed to help students study efficiently by summarizing long documents and lecture videos, and generating questions to evaluate their understanding of the subject. The output notes and flashcards can also be saved as PDFs for easy review and sharing.\u003c/p\u003e\n\u003cp\u003eThis project was developed collaboratively as a team effort. My role included:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eProject Manager\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eBackend Development\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFront-End Design\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"features\"\u003eFeatures\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eSummarizes lengthy documents and lecture videos into concise notes.\u003c/li\u003e\n\u003cli\u003eGenerates questions and flashcards to test student comprehension.\u003c/li\u003e\n\u003cli\u003eAllows users to save notes and flashcards as PDF files.\u003c/li\u003e\n\u003cli\u003eAsk AI questions about the lecture and get answers using AI.\u003c/li\u003e\n\u003cli\u003eUser-friendly web interface built with Streamlit.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"my-contributions\"\u003eMy Contributions\u003c/h1\u003e\n\u003cp\u003eAs the project manager, I coordinated the team and ensured timely delivery of milestones. I also led the backend development, integrating LangChain and GPT-4o-mini for advanced summarization and question generation. Additionally, I contributed to the front-end design, focusing on usability and accessibility.\u003c/p\u003e\n\u003ch1 id=\"screenshots\"\u003eScreenshots\u003c/h1\u003e\n\u003cp\u003eHere are some screenshots of the website:\u003c/p\u003e\n\u003cdiv align=\"center\" style=\"margin-bottom: 1.5rem;\"\u003e\n  \u003cimg src=\"/images/projects/notecraft-landing.png\" alt=\"Landing Page\" style=\"max-width: 800px; width: 90%; display: block; margin: 0 auto 1.5rem auto;\" /\u003e\n\u003c/div\u003e\n\u003cdiv align=\"center\"\u003e\n  \u003cimg src=\"/images/projects/note-gen-page.png\" alt=\"Note Generation Page\" style=\"max-width: 800px; width: 90%; display: block; margin: 0 auto;\" /\u003e\n\u003c/div\u003e\n\u003chr\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/AL-Sayed1/NoteCraft\" target=\"_blank\" rel=\"noopener\"\u003e\u003cstrong\u003eView code on GitHub\u003c/strong\u003e\u003c/a\u003e\u003c/p\u003e\n","description":"","image":"/images/projects/notecraft-landing.png","permalink":"https://al-sayed1.github.io/projects/notecraft-ai/","title":"NoteCraft AI"},{"content":"","description":"My gallery :earth_asia:","image":null,"permalink":"https://al-sayed1.github.io/gallery/","title":"Image Gallery"}]